{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba28b230",
   "metadata": {},
   "source": [
    "Build a text classification model using the Naive Bayes algorithm to categorize the blog posts accurately. Furthermore, perform sentiment analysis to understand the general sentiment (positive, negative, neutral) expressed in these posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0675d6",
   "metadata": {},
   "source": [
    "# Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6acfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings                   # import library warnings\n",
    "warnings.filterwarnings('ignore')  # it will ignore warnings in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffea3de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data       Labels\n",
       "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
       "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
       "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
       "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
       "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r'blogs.csv', header=0)  # load dataset, 0th row as a header\n",
    "data.head() # display top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5e1631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Data    2000 non-null   object\n",
      " 1   Labels  2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info() # gives info about null values and data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ef5923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data      0\n",
       "Labels    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()  # there is no null value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4606fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data      object\n",
       "Labels    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes # data type in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40a7f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape  # rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a492c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Data, Labels]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated()] # display the duplicated row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ff314",
   "metadata": {},
   "source": [
    "there is no duplicate row in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a300132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
       "       'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
       "       'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles',\n",
       "       'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',\n",
       "       'sci.electronics', 'sci.med', 'sci.space',\n",
       "       'soc.religion.christian', 'talk.politics.guns',\n",
       "       'talk.politics.mideast', 'talk.politics.misc',\n",
       "       'talk.religion.misc'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Labels'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90867169",
   "metadata": {},
   "source": [
    "# convert the Labels into numbers using LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a20b7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = ['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eff6d707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Labels\n",
      "mapping {'alt.atheism': 0, 'comp.graphics': 1, 'comp.os.ms-windows.misc': 2, 'comp.sys.ibm.pc.hardware': 3, 'comp.sys.mac.hardware': 4, 'comp.windows.x': 5, 'misc.forsale': 6, 'rec.autos': 7, 'rec.motorcycles': 8, 'rec.sport.baseball': 9, 'rec.sport.hockey': 10, 'sci.crypt': 11, 'sci.electronics': 12, 'sci.med': 13, 'sci.space': 14, 'soc.religion.christian': 15, 'talk.politics.guns': 16, 'talk.politics.mideast': 17, 'talk.politics.misc': 18, 'talk.religion.misc': 19}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder # import LabelEncoder function from preprocessing sublibrary\n",
    "le=LabelEncoder()                              # save LabelEncoder function in a variable le\n",
    "for x in colname:                             \n",
    "    data[x]=le.fit_transform(data[x]) # it assigns numbers to all values of categorical column\n",
    "    le_name_mapping = dict(zip(le.classes_,le.transform(le.classes_)))  # represent in a dictionary\n",
    "    print('Feature',x)\n",
    "    print('mapping',le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c30cbd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data  Labels\n",
       "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...       0\n",
       "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....       0\n",
       "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...       0\n",
       "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...       0\n",
       "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27ee2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     100\n",
       "1     100\n",
       "18    100\n",
       "17    100\n",
       "16    100\n",
       "15    100\n",
       "14    100\n",
       "13    100\n",
       "12    100\n",
       "11    100\n",
       "10    100\n",
       "9     100\n",
       "8     100\n",
       "7     100\n",
       "6     100\n",
       "5     100\n",
       "4     100\n",
       "3     100\n",
       "2     100\n",
       "19    100\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labels count: \n",
    "data['Labels'].value_counts() # our dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c0e507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...\n",
       "1       Newsgroups: alt.atheism\\nPath: cantaloupe.srv....\n",
       "2       Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...\n",
       "3       Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...\n",
       "4       Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...\n",
       "                              ...                        \n",
       "1995    Xref: cantaloupe.srv.cs.cmu.edu talk.abortion:...\n",
       "1996    Xref: cantaloupe.srv.cs.cmu.edu talk.religion....\n",
       "1997    Xref: cantaloupe.srv.cs.cmu.edu talk.origins:4...\n",
       "1998    Xref: cantaloupe.srv.cs.cmu.edu talk.religion....\n",
       "1999    Xref: cantaloupe.srv.cs.cmu.edu sci.skeptic:43...\n",
       "Name: Data, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885599ef",
   "metadata": {},
   "source": [
    "# \tPreprocess the data by cleaning the text (removing punctuation, converting to lowercase, etc.), tokenizing, and removing stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707cf184",
   "metadata": {},
   "source": [
    "Let's remove the non-alphanumeric characters i.e. special characters (like @, #, $ etc.) from the dataset using regex function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fcde99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # regex function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "145de78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(string):\n",
    "    result = re.sub('','',string)          #remove HTML tags \n",
    "    result = re.sub('https://.*','',result)   #remove URLs\n",
    "    result = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", result) # remove special characters in result & replace them with a blank space\n",
    "    result = result.lower()  # convert text to lowercase\n",
    "    return result # after execution of return statement, interpreter will come out of the function and go to the location where the func. is called\n",
    "\n",
    "data['Data']=data['Data'].apply(lambda cw : remove_tags(cw)) # apply func used to apply lambda func to a dataframe, remove_tags()func is called & cw will copy over string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7011fdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       path  cantaloupe srv cs cmu edu magnesium club...\n",
       "1       newsgroups  alt atheism path  cantaloupe srv c...\n",
       "2       path  cantaloupe srv cs cmu edu das news harva...\n",
       "3       path  cantaloupe srv cs cmu edu magnesium club...\n",
       "4       xref  cantaloupe srv cs cmu edu alt atheism 53...\n",
       "                              ...                        \n",
       "1995    xref  cantaloupe srv cs cmu edu talk abortion ...\n",
       "1996    xref  cantaloupe srv cs cmu edu talk religion ...\n",
       "1997    xref  cantaloupe srv cs cmu edu talk origins 4...\n",
       "1998    xref  cantaloupe srv cs cmu edu talk religion ...\n",
       "1999    xref  cantaloupe srv cs cmu edu sci skeptic 43...\n",
       "Name: Data, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Data']   # we can see now Data column doesn't have special characters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc21fc",
   "metadata": {},
   "source": [
    "# Remove stop words . Stop words don't hold any special meaning in a sentence like 'and', 'the' etc. So, we should remove them using nltk library which has stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf6f8fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nitin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk  # nltk lib. (Natural Language Toolkit)\n",
    "nltk.download('stopwords') # download stopwords package to sublib. corpus \n",
    "from nltk.corpus import stopwords # import stopwords func. from sublib. corpus \n",
    "stop_words = set(stopwords.words('english')) # list of stop words in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c17d6c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words # list of stop words in english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcbcaa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words \n",
    "# join words in Data column with a blank space if they are not in stopwords list \n",
    "data['Data'] = data['Data'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8ff14a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       path cantaloupe srv cs cmu edu magnesium club ...\n",
       "1       newsgroups alt atheism path cantaloupe srv cs ...\n",
       "2       path cantaloupe srv cs cmu edu das news harvar...\n",
       "3       path cantaloupe srv cs cmu edu magnesium club ...\n",
       "4       xref cantaloupe srv cs cmu edu alt atheism 534...\n",
       "                              ...                        \n",
       "1995    xref cantaloupe srv cs cmu edu talk abortion 1...\n",
       "1996    xref cantaloupe srv cs cmu edu talk religion m...\n",
       "1997    xref cantaloupe srv cs cmu edu talk origins 41...\n",
       "1998    xref cantaloupe srv cs cmu edu talk religion m...\n",
       "1999    xref cantaloupe srv cs cmu edu sci skeptic 435...\n",
       "Name: Data, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Data']  # now Data column doesn't have stop words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190c227",
   "metadata": {},
   "source": [
    "# Now, we perform lemmatization on the text column. Lemmatization is used to find the root form of words in NLP, for ex: root form of the words: reading, reads, read is read. This save unnecessary computational cost in decoding the entire words.\n",
    "\n",
    "In lemmatization, text convert into tokens/words and then each token convert into root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec992011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nitin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nitin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet') # download package wordnet to sublib. stem\n",
    "nltk.download('omw-1.4') # download package omw-1.4 to sublib. tokenize \n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer() # save function in a variable \n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(sentence): # define a func and pass sentence in it \n",
    "    st = \"\"    # empty string \n",
    "    for w in w_tokenizer.tokenize(sentence):   # convert text into tokens using WhitespaceTokenizer() func saved in var. w_tokenizer \n",
    "        st = st + lemmatizer.lemmatize(w) + \" \"   # convert token into root form using WordNetLemmatizer() func saved in var. lemmatizer  \n",
    "    return st\n",
    "data['Data'] = data['Data'].apply(lambda t: lemmatize_text(t)) # func. is called, t will copy over sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee3a08fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       path cantaloupe srv c cmu edu magnesium club c...\n",
       "1       newsgroups alt atheism path cantaloupe srv c c...\n",
       "2       path cantaloupe srv c cmu edu da news harvard ...\n",
       "3       path cantaloupe srv c cmu edu magnesium club c...\n",
       "4       xref cantaloupe srv c cmu edu alt atheism 5348...\n",
       "                              ...                        \n",
       "1995    xref cantaloupe srv c cmu edu talk abortion 12...\n",
       "1996    xref cantaloupe srv c cmu edu talk religion mi...\n",
       "1997    xref cantaloupe srv c cmu edu talk origin 4103...\n",
       "1998    xref cantaloupe srv c cmu edu talk religion mi...\n",
       "1999    xref cantaloupe srv c cmu edu sci skeptic 4356...\n",
       "Name: Data, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Data']  # we can see Data column has root form of words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05952c0c",
   "metadata": {},
   "source": [
    "classify the blog posts into different categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce43d3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newsgroups alt atheism path cantaloupe srv c c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>path cantaloupe srv c cmu edu da news harvard ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xref cantaloupe srv c cmu edu alt atheism 5348...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data  Labels\n",
       "0  path cantaloupe srv c cmu edu magnesium club c...       0\n",
       "1  newsgroups alt atheism path cantaloupe srv c c...       0\n",
       "2  path cantaloupe srv c cmu edu da news harvard ...       0\n",
       "3  path cantaloupe srv c cmu edu magnesium club c...       0\n",
       "4  xref cantaloupe srv c cmu edu alt atheism 5348...       0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee39da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and Y\n",
    "X = data['Data']\n",
    "Y = data['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0df4d66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       path cantaloupe srv c cmu edu magnesium club c...\n",
       "1       newsgroups alt atheism path cantaloupe srv c c...\n",
       "2       path cantaloupe srv c cmu edu da news harvard ...\n",
       "3       path cantaloupe srv c cmu edu magnesium club c...\n",
       "4       xref cantaloupe srv c cmu edu alt atheism 5348...\n",
       "                              ...                        \n",
       "1995    xref cantaloupe srv c cmu edu talk abortion 12...\n",
       "1996    xref cantaloupe srv c cmu edu talk religion mi...\n",
       "1997    xref cantaloupe srv c cmu edu talk origin 4103...\n",
       "1998    xref cantaloupe srv c cmu edu talk religion mi...\n",
       "1999    xref cantaloupe srv c cmu edu sci skeptic 4356...\n",
       "Name: Data, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e32a6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "1995    19\n",
       "1996    19\n",
       "1997    19\n",
       "1998    19\n",
       "1999    19\n",
       "Name: Labels, Length: 2000, dtype: int32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf191f",
   "metadata": {},
   "source": [
    "# Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93a93815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "# 75% training set, 25% testing set \n",
    "# stratify = Y will make sure that random split has same proportion of classes in both training(Y_train) & testing set(Y_test) \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,stratify=Y, test_size=0.25,random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "973e4b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n",
      "(500,)\n",
      "(1500,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a149a63",
   "metadata": {},
   "source": [
    "# Perform feature extraction to convert text data into a format that can be used by the Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696429e6",
   "metadata": {},
   "source": [
    "# vectorize text to numbers using func. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "617287c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # import CountVectorizer func\n",
    "vec = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "371bac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad053041",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vec.fit_transform(X_train).toarray() # convert X_train into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddb05120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad442cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vec.transform(X_test).toarray() # convert X_test into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "284d3468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d6e04",
   "metadata": {},
   "source": [
    "# Implement a Naive Bayes classifier to categorize the blog posts into their respective categories. We can use libraries like scikit-learn for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acd14062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will fit the Naive Bayes model to the training data\n",
    "from sklearn.naive_bayes import MultinomialNB   # multinomial for multiple classes, Gaussian for binary classes\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd13f653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa138321",
   "metadata": {},
   "source": [
    "# Train the model on the training set and make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f091e694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,Y_train)  # train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e597f721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966666666666667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, Y_train) # score of the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23ba4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will predict the test data \n",
    "Y_pred = classifier.predict(X_test) # predict the class of Y for the given testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dc7b6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 19, 11, 10,  5, 19,  8,  1,  8,  1, 15, 17, 16,  7, 17,  8,  6,\n",
       "       10,  4,  7, 12,  2,  0,  3,  2,  3, 13,  9, 11,  9, 18, 12,  2, 13,\n",
       "        8, 12,  5,  2, 14, 11, 14, 13,  2, 13, 17, 15, 10, 14,  3,  2, 17,\n",
       "       19, 15, 18,  7, 19, 17,  9, 17,  1,  7, 18, 19, 16,  4,  2, 16, 15,\n",
       "       17, 15, 14, 18,  9, 13,  5, 18, 16, 14,  5,  8,  1,  9,  5, 14, 19,\n",
       "        0, 11,  4, 15, 14,  6, 11,  3,  1, 14, 19,  5,  7, 15,  4, 18, 17,\n",
       "        1, 17,  3,  9,  7,  9, 19, 10, 16, 10,  7, 19,  3,  6, 16,  2, 19,\n",
       "       19,  2, 14, 14,  3, 14, 11, 16, 17,  2,  5,  3,  6,  9,  2, 11,  7,\n",
       "        1,  3,  7,  4, 13,  3,  0, 11, 13,  6,  3,  4,  5,  3, 12, 19, 11,\n",
       "        3, 18,  0,  6, 11,  2, 18, 10,  0,  4,  9, 13,  1, 11, 19, 13, 13,\n",
       "       12,  8,  3,  2,  7, 13, 13, 18, 10, 19,  1,  4, 13,  4, 16, 17, 11,\n",
       "       16,  5, 14, 15, 14, 18,  3, 10, 12,  8,  3,  0,  6,  4, 14, 10,  3,\n",
       "       16, 14, 18, 10,  5, 15, 18,  7,  0, 15, 19,  6,  2, 10, 11, 15,  3,\n",
       "        1,  8, 11, 15,  5,  2, 19,  9, 17,  1,  6, 17,  8, 19,  5, 10, 11,\n",
       "       16,  8, 10,  7,  6,  7, 17, 15, 13,  3, 18, 15, 15, 12, 17, 17, 12,\n",
       "       11,  9, 17,  9,  6,  1, 18, 16, 15, 10, 17,  6, 11, 10,  4,  3, 19,\n",
       "        1, 16, 11,  1, 15,  1, 16, 17, 17, 12, 12, 13, 10, 12, 18, 15,  5,\n",
       "       12,  0, 18,  0, 10, 14,  8, 14, 10, 18,  4, 14,  6, 18, 18, 16, 13,\n",
       "        9,  8, 13,  9,  9, 10,  5, 12,  2,  1, 14, 13, 11, 11,  5,  8, 19,\n",
       "       18,  3, 16, 10, 15, 19,  4, 17,  9,  8,  3, 18, 18,  8, 18,  8, 18,\n",
       "        7,  2,  4, 16,  7, 19, 19,  1, 17,  2, 17,  3,  5,  4, 19,  4,  2,\n",
       "        6,  6, 12, 12, 15,  7,  2, 13,  8, 11, 16,  3, 10, 12, 13,  9,  3,\n",
       "        1, 16, 14, 18, 19, 14,  8, 13, 17,  4,  0, 10,  2,  8, 18, 18, 19,\n",
       "       19, 13, 18, 14,  7,  0, 14,  6,  5,  2,  2,  0,  2,  1, 18,  7, 13,\n",
       "        1,  8, 11, 12, 10, 17, 16, 19, 10,  8,  9, 18, 12, 17,  2,  9,  7,\n",
       "        4,  5,  2, 15,  4,  8, 15, 11, 18, 16,  4,  7,  0, 12, 18, 18,  5,\n",
       "       15, 10,  6, 14,  5, 16,  3,  0, 18,  4,  3,  2,  1, 18, 16, 19, 15,\n",
       "       10,  2, 14,  2, 14, 16, 10, 15, 18, 17, 11, 10,  0,  4,  7,  7,  1,\n",
       "        6, 10,  2,  8,  5,  7, 15,  5,  9,  5,  0, 15, 19,  1,  0, 11,  2,\n",
       "        2,  6,  1, 13, 19, 12, 11])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25bb0ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 9), (19, 19), (12, 11), (10, 10), (5, 5), (19, 19), (8, 8), (13, 1), (8, 8), (1, 1), (15, 15), (18, 17), (16, 16), (8, 7), (17, 17), (8, 8), (6, 6), (12, 10), (4, 4), (7, 7), (12, 12), (2, 2), (0, 0), (3, 3), (6, 2), (3, 3), (13, 13), (9, 9), (11, 11), (9, 9), (18, 18), (12, 12), (2, 2), (13, 13), (8, 8), (12, 12), (5, 5), (2, 2), (14, 14), (11, 11), (14, 14), (13, 13), (2, 2), (13, 13), (17, 17), (15, 15), (10, 10), (14, 14), (3, 3), (2, 2), (17, 17), (19, 19), (15, 15), (16, 18), (7, 7), (0, 19), (17, 17), (9, 9), (18, 17), (4, 1), (7, 7), (16, 18), (19, 19), (16, 16), (4, 4), (2, 2), (16, 16), (15, 15), (17, 17), (15, 15), (14, 14), (19, 18), (9, 9), (13, 13), (5, 5), (18, 18), (16, 16), (14, 14), (5, 5), (8, 8), (1, 1), (9, 9), (1, 5), (14, 14), (19, 19), (0, 0), (11, 11), (4, 4), (15, 15), (14, 14), (6, 6), (11, 11), (3, 3), (1, 1), (14, 14), (19, 19), (5, 5), (7, 7), (15, 15), (4, 4), (10, 18), (17, 17), (1, 1), (17, 17), (3, 3), (9, 9), (7, 7), (9, 9), (19, 19), (10, 10), (16, 16), (7, 10), (7, 7), (19, 19), (3, 3), (6, 6), (19, 16), (3, 2), (0, 19), (0, 19), (3, 2), (12, 14), (19, 14), (3, 3), (14, 14), (11, 11), (16, 16), (17, 17), (2, 2), (1, 5), (3, 3), (6, 6), (9, 9), (2, 2), (11, 11), (7, 7), (1, 1), (3, 3), (7, 7), (4, 4), (13, 13), (3, 3), (0, 0), (11, 11), (13, 13), (6, 6), (3, 3), (3, 4), (2, 5), (1, 3), (12, 12), (19, 19), (11, 11), (4, 3), (18, 18), (0, 0), (6, 6), (11, 11), (4, 2), (6, 18), (10, 10), (0, 0), (4, 4), (9, 9), (6, 13), (1, 1), (11, 11), (18, 19), (16, 13), (13, 13), (12, 12), (8, 8), (3, 3), (2, 2), (7, 7), (13, 13), (13, 13), (17, 18), (10, 10), (19, 19), (1, 1), (4, 4), (13, 13), (12, 4), (16, 16), (17, 17), (11, 11), (16, 16), (5, 5), (14, 14), (15, 15), (14, 14), (13, 18), (5, 3), (10, 10), (12, 12), (8, 8), (3, 3), (0, 0), (6, 6), (4, 4), (14, 14), (10, 10), (3, 3), (8, 16), (14, 14), (7, 18), (9, 10), (5, 5), (15, 15), (18, 18), (7, 7), (0, 0), (15, 15), (19, 19), (12, 6), (2, 2), (10, 10), (11, 11), (15, 15), (4, 3), (1, 1), (8, 8), (11, 11), (15, 15), (5, 5), (2, 2), (0, 19), (9, 9), (17, 17), (1, 1), (6, 6), (17, 17), (8, 8), (19, 19), (5, 5), (10, 10), (11, 11), (16, 16), (8, 8), (10, 10), (7, 7), (6, 6), (7, 7), (17, 17), (15, 15), (13, 13), (3, 3), (18, 18), (15, 15), (15, 15), (12, 12), (17, 17), (18, 17), (3, 12), (11, 11), (9, 9), (17, 17), (9, 9), (6, 6), (1, 1), (13, 18), (7, 16), (0, 15), (10, 10), (17, 17), (6, 6), (11, 11), (10, 10), (4, 4), (6, 3), (19, 19), (1, 1), (16, 16), (11, 11), (1, 1), (15, 15), (5, 1), (16, 16), (17, 17), (17, 17), (12, 12), (12, 12), (13, 13), (10, 10), (12, 12), (18, 18), (15, 15), (5, 5), (14, 12), (0, 0), (18, 18), (19, 0), (10, 10), (14, 14), (8, 8), (14, 14), (9, 10), (18, 18), (4, 4), (14, 14), (6, 6), (14, 18), (17, 18), (16, 16), (13, 13), (9, 9), (8, 8), (13, 13), (9, 9), (9, 9), (10, 10), (5, 5), (12, 12), (1, 2), (1, 1), (12, 14), (13, 13), (11, 11), (11, 11), (5, 5), (8, 8), (16, 19), (19, 18), (3, 3), (16, 16), (10, 10), (0, 15), (0, 19), (4, 4), (17, 17), (9, 9), (8, 8), (16, 3), (6, 18), (18, 18), (8, 8), (12, 18), (8, 8), (7, 18), (7, 7), (2, 2), (4, 4), (7, 16), (7, 7), (18, 19), (19, 19), (12, 1), (17, 17), (3, 2), (17, 17), (5, 3), (5, 5), (4, 4), (19, 19), (4, 4), (5, 2), (6, 6), (6, 6), (12, 12), (12, 12), (15, 15), (12, 7), (3, 2), (13, 13), (8, 8), (11, 11), (16, 16), (3, 3), (10, 10), (6, 12), (13, 13), (9, 9), (3, 3), (1, 1), (8, 16), (14, 14), (18, 18), (19, 19), (14, 14), (9, 8), (13, 13), (17, 17), (4, 4), (0, 0), (10, 10), (2, 2), (8, 8), (18, 18), (18, 18), (19, 19), (0, 19), (13, 13), (18, 18), (14, 14), (7, 7), (0, 0), (14, 14), (6, 6), (5, 5), (2, 2), (2, 2), (0, 0), (2, 2), (1, 1), (18, 18), (7, 7), (13, 13), (1, 1), (8, 8), (11, 11), (12, 12), (10, 10), (16, 17), (16, 16), (0, 19), (10, 10), (6, 8), (9, 9), (16, 18), (12, 12), (17, 17), (2, 2), (9, 9), (8, 7), (4, 4), (1, 5), (2, 2), (15, 15), (4, 4), (8, 8), (15, 15), (11, 11), (18, 18), (16, 16), (4, 4), (7, 7), (0, 0), (12, 12), (18, 18), (18, 18), (5, 5), (15, 15), (9, 10), (6, 6), (14, 14), (5, 5), (16, 16), (2, 3), (0, 0), (18, 18), (4, 4), (3, 3), (2, 2), (1, 1), (18, 18), (6, 16), (19, 19), (15, 15), (10, 10), (2, 2), (14, 14), (2, 2), (14, 14), (16, 16), (10, 10), (15, 15), (18, 18), (17, 17), (11, 11), (10, 10), (0, 0), (4, 4), (7, 7), (7, 7), (1, 1), (6, 6), (10, 10), (5, 2), (8, 8), (5, 5), (7, 7), (15, 15), (5, 5), (9, 9), (5, 5), (19, 0), (15, 15), (0, 19), (1, 1), (0, 0), (11, 11), (2, 2), (2, 2), (5, 6), (1, 1), (13, 13), (19, 19), (4, 12), (11, 11)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(Y_test, Y_pred))) # compare actual Y with predicted Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edbf34cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  8]\n",
      " [ 0 20  1  1  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 23  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  4 19  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  2 20  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  2  2  0 19  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  0  0 17  0  1  0  0  0  1  1  0  0  1  0  2  0]\n",
      " [ 0  0  0  0  0  0  0 20  0  0  1  0  0  0  0  0  2  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  2 21  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1 21  3  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 24  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  1  0  1  1  0  0  1  1 16  0  2  0  0  0  1  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 23  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0 18  1  3  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3 20  2]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  2 19]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.60      0.71        25\n",
      "           1       0.83      0.80      0.82        25\n",
      "           2       0.72      0.92      0.81        25\n",
      "           3       0.70      0.76      0.73        25\n",
      "           4       0.91      0.80      0.85        25\n",
      "           5       0.83      0.76      0.79        25\n",
      "           6       0.89      0.68      0.77        25\n",
      "           7       0.87      0.80      0.83        25\n",
      "           8       0.91      0.84      0.87        25\n",
      "           9       1.00      0.84      0.91        25\n",
      "          10       0.83      0.96      0.89        25\n",
      "          11       0.96      1.00      0.98        25\n",
      "          12       0.80      0.64      0.71        25\n",
      "          13       0.92      0.88      0.90        25\n",
      "          14       0.88      0.92      0.90        25\n",
      "          15       0.93      1.00      0.96        25\n",
      "          16       0.75      0.72      0.73        25\n",
      "          17       0.85      0.92      0.88        25\n",
      "          18       0.56      0.80      0.66        25\n",
      "          19       0.63      0.76      0.69        25\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.83      0.82      0.82       500\n",
      "weighted avg       0.83      0.82      0.82       500\n",
      "\n",
      "Multinomial Naive Bayes model accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# model evaluation \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report # import these functions from metrics sublib.\n",
    "cfm = confusion_matrix(Y_test,Y_pred)  #confusion matrix\n",
    "print(cfm)\n",
    "\n",
    "print('classification report')  # classification report\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc = accuracy_score(Y_test,Y_pred)  # accuracy of the model\n",
    "print('Multinomial Naive Bayes model accuracy:',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ec3ba",
   "metadata": {},
   "source": [
    "accuracy of our model on testing data is 0.82 which is very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94b5f2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model validating \n",
    "classifier.predict(vec.transform(['Newsgroups: alt.atheism']).toarray())  # we can pass any text for testing our model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdcc426",
   "metadata": {},
   "source": [
    "0 means category 'alt.atheism' which is also confirmed by our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e747271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(vec.transform(['Xref: cantaloupe.srv.cs.cmu.edu comp.graphics:38728']).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b23941",
   "metadata": {},
   "source": [
    "1 means category 'comp.graphics' which is also confirmed by our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcc54d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(vec.transform(['Association of the United States has alerted the Defense Base']).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0734b",
   "metadata": {},
   "source": [
    "11 means category 'sci.crypt' which is also confirmed by our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5cc08",
   "metadata": {},
   "source": [
    "Our model is making correct predictions. So, our model can classify an unseen data as one of the above given categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c84b24",
   "metadata": {},
   "source": [
    "# perform sentiment analysis to understand the general sentiment (positive, negative, neutral) expressed in these posts i.e. classify the blog post as positive, negative or neutral using SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc3124a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newsgroups alt atheism path cantaloupe srv c c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>path cantaloupe srv c cmu edu da news harvard ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xref cantaloupe srv c cmu edu alt atheism 5348...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data  Labels\n",
       "0  path cantaloupe srv c cmu edu magnesium club c...       0\n",
       "1  newsgroups alt atheism path cantaloupe srv c c...       0\n",
       "2  path cantaloupe srv c cmu edu da news harvard ...       0\n",
       "3  path cantaloupe srv c cmu edu magnesium club c...       0\n",
       "4  xref cantaloupe srv c cmu edu alt atheism 5348...       0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1fcf766d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\nitin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# nltk lib. has vader lexicon sub lib. which has SentimentIntensityAnalyzer func. \n",
    "#SentimentIntensityAnalyzer func runs the entire NLP pipeline to do sentiment analysis of any sentence  \n",
    "nltk.download(\"vader_lexicon\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()  # initialise SentimentIntensityAnalyzer func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ff56bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.178, 'neu': 0.68, 'pos': 0.142, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newsgroups alt atheism path cantaloupe srv c c...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.015, 'neu': 0.871, 'pos': 0.115, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>path cantaloupe srv c cmu edu da news harvard ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.18, 'neu': 0.747, 'pos': 0.074, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.257, 'neu': 0.59, 'pos': 0.153, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xref cantaloupe srv c cmu edu alt atheism 5348...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.027, 'neu': 0.859, 'pos': 0.114, 'co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data  Labels  \\\n",
       "0  path cantaloupe srv c cmu edu magnesium club c...       0   \n",
       "1  newsgroups alt atheism path cantaloupe srv c c...       0   \n",
       "2  path cantaloupe srv c cmu edu da news harvard ...       0   \n",
       "3  path cantaloupe srv c cmu edu magnesium club c...       0   \n",
       "4  xref cantaloupe srv c cmu edu alt atheism 5348...       0   \n",
       "\n",
       "                                               score  \n",
       "0  {'neg': 0.178, 'neu': 0.68, 'pos': 0.142, 'com...  \n",
       "1  {'neg': 0.015, 'neu': 0.871, 'pos': 0.115, 'co...  \n",
       "2  {'neg': 0.18, 'neu': 0.747, 'pos': 0.074, 'com...  \n",
       "3  {'neg': 0.257, 'neu': 0.59, 'pos': 0.153, 'com...  \n",
       "4  {'neg': 0.027, 'neu': 0.859, 'pos': 0.114, 'co...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply lambda function to a dataframe\n",
    "# sid method has polarity_scores function that returns a dictionary of sentiment scores when we pass review as input \n",
    "# add a new column score that has dictionary of sentiment scores\n",
    "\n",
    "data[\"score\"] = data[\"Data\"].apply(lambda review:sid.polarity_scores(review))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae2eb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since, overall sentiment of the text given by compound score. So, retrieve the compound score from the score column\n",
    "# add a new column compound which has compound scores \n",
    "data[\"compound\"] = data[\"score\"].apply(lambda d:d[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "039eb6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "      <th>score</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.178, 'neu': 0.68, 'pos': 0.142, 'com...</td>\n",
       "      <td>-0.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newsgroups alt atheism path cantaloupe srv c c...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.015, 'neu': 0.871, 'pos': 0.115, 'co...</td>\n",
       "      <td>0.9251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>path cantaloupe srv c cmu edu da news harvard ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.18, 'neu': 0.747, 'pos': 0.074, 'com...</td>\n",
       "      <td>-0.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.257, 'neu': 0.59, 'pos': 0.153, 'com...</td>\n",
       "      <td>-0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xref cantaloupe srv c cmu edu alt atheism 5348...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.027, 'neu': 0.859, 'pos': 0.114, 'co...</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data  Labels  \\\n",
       "0  path cantaloupe srv c cmu edu magnesium club c...       0   \n",
       "1  newsgroups alt atheism path cantaloupe srv c c...       0   \n",
       "2  path cantaloupe srv c cmu edu da news harvard ...       0   \n",
       "3  path cantaloupe srv c cmu edu magnesium club c...       0   \n",
       "4  xref cantaloupe srv c cmu edu alt atheism 5348...       0   \n",
       "\n",
       "                                               score  compound  \n",
       "0  {'neg': 0.178, 'neu': 0.68, 'pos': 0.142, 'com...   -0.9904  \n",
       "1  {'neg': 0.015, 'neu': 0.871, 'pos': 0.115, 'co...    0.9251  \n",
       "2  {'neg': 0.18, 'neu': 0.747, 'pos': 0.074, 'com...   -0.9900  \n",
       "3  {'neg': 0.257, 'neu': 0.59, 'pos': 0.153, 'com...   -0.9997  \n",
       "4  {'neg': 0.027, 'neu': 0.859, 'pos': 0.114, 'co...    0.9778  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22cf26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to classify the blog posts as positive, negative or neutral post using compound score\n",
    "def blog_sentiment(compound_score):  \n",
    "\n",
    "    if compound_score > 0:\n",
    "        return 'positive'\n",
    "    elif compound_score == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "data[\"sentiment\"] = data[\"compound\"].apply(lambda s : blog_sentiment(s)) # function is called and s will copy over compound_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3edaad87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "      <th>score</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.178, 'neu': 0.68, 'pos': 0.142, 'com...</td>\n",
       "      <td>-0.9904</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newsgroups alt atheism path cantaloupe srv c c...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.015, 'neu': 0.871, 'pos': 0.115, 'co...</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>path cantaloupe srv c cmu edu da news harvard ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.18, 'neu': 0.747, 'pos': 0.074, 'com...</td>\n",
       "      <td>-0.9900</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.257, 'neu': 0.59, 'pos': 0.153, 'com...</td>\n",
       "      <td>-0.9997</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xref cantaloupe srv c cmu edu alt atheism 5348...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.027, 'neu': 0.859, 'pos': 0.114, 'co...</td>\n",
       "      <td>0.9778</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data  Labels  \\\n",
       "0  path cantaloupe srv c cmu edu magnesium club c...       0   \n",
       "1  newsgroups alt atheism path cantaloupe srv c c...       0   \n",
       "2  path cantaloupe srv c cmu edu da news harvard ...       0   \n",
       "3  path cantaloupe srv c cmu edu magnesium club c...       0   \n",
       "4  xref cantaloupe srv c cmu edu alt atheism 5348...       0   \n",
       "\n",
       "                                               score  compound sentiment  \n",
       "0  {'neg': 0.178, 'neu': 0.68, 'pos': 0.142, 'com...   -0.9904  negative  \n",
       "1  {'neg': 0.015, 'neu': 0.871, 'pos': 0.115, 'co...    0.9251  positive  \n",
       "2  {'neg': 0.18, 'neu': 0.747, 'pos': 0.074, 'com...   -0.9900  negative  \n",
       "3  {'neg': 0.257, 'neu': 0.59, 'pos': 0.153, 'com...   -0.9997  negative  \n",
       "4  {'neg': 0.027, 'neu': 0.859, 'pos': 0.114, 'co...    0.9778  positive  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82236fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['Labels']   # delete Labels column\n",
    "del data[\"score\"]    # delete score column\n",
    "del data[\"compound\"]  # delete compound column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d227fe00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newsgroups alt atheism path cantaloupe srv c c...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>path cantaloupe srv c cmu edu da news harvard ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xref cantaloupe srv c cmu edu alt atheism 5348...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data sentiment\n",
       "0  path cantaloupe srv c cmu edu magnesium club c...  negative\n",
       "1  newsgroups alt atheism path cantaloupe srv c c...  positive\n",
       "2  path cantaloupe srv c cmu edu da news harvard ...  negative\n",
       "3  path cantaloupe srv c cmu edu magnesium club c...  negative\n",
       "4  xref cantaloupe srv c cmu edu alt atheism 5348...  positive"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9406cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f3ac6b",
   "metadata": {},
   "source": [
    "# apply LabelEncoding on sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "211a99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature sentiment\n",
      "mapping {'negative': 0, 'neutral': 1, 'positive': 2}\n"
     ]
    }
   ],
   "source": [
    "colname = ['sentiment']\n",
    "from sklearn.preprocessing import LabelEncoder # import LabelEncoder function from preprocessing sublibrary\n",
    "le=LabelEncoder()                              # save LabelEncoder function in a variable le\n",
    "for x in colname:                             \n",
    "    data[x]=le.fit_transform(data[x]) # it assigns numbers to all values of categorical column\n",
    "    le_name_mapping = dict(zip(le.classes_,le.transform(le.classes_)))  # represent in a dictionary\n",
    "    print('Feature',x)\n",
    "    print('mapping',le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36a022d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newsgroups alt atheism path cantaloupe srv c c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>path cantaloupe srv c cmu edu da news harvard ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>path cantaloupe srv c cmu edu magnesium club c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xref cantaloupe srv c cmu edu alt atheism 5348...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data  sentiment\n",
       "0  path cantaloupe srv c cmu edu magnesium club c...          0\n",
       "1  newsgroups alt atheism path cantaloupe srv c c...          2\n",
       "2  path cantaloupe srv c cmu edu da news harvard ...          0\n",
       "3  path cantaloupe srv c cmu edu magnesium club c...          0\n",
       "4  xref cantaloupe srv c cmu edu alt atheism 5348...          2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b40446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and Y\n",
    "X = data['Data']\n",
    "Y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d9f6570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       path cantaloupe srv c cmu edu magnesium club c...\n",
       "1       newsgroups alt atheism path cantaloupe srv c c...\n",
       "2       path cantaloupe srv c cmu edu da news harvard ...\n",
       "3       path cantaloupe srv c cmu edu magnesium club c...\n",
       "4       xref cantaloupe srv c cmu edu alt atheism 5348...\n",
       "                              ...                        \n",
       "1995    xref cantaloupe srv c cmu edu talk abortion 12...\n",
       "1996    xref cantaloupe srv c cmu edu talk religion mi...\n",
       "1997    xref cantaloupe srv c cmu edu talk origin 4103...\n",
       "1998    xref cantaloupe srv c cmu edu talk religion mi...\n",
       "1999    xref cantaloupe srv c cmu edu sci skeptic 4356...\n",
       "Name: Data, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee0560eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       2\n",
       "2       0\n",
       "3       0\n",
       "4       2\n",
       "       ..\n",
       "1995    2\n",
       "1996    2\n",
       "1997    2\n",
       "1998    2\n",
       "1999    0\n",
       "Name: sentiment, Length: 2000, dtype: int32"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ace277c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "# 75% training set, 25% testing set \n",
    "# stratify = Y will make sure that random split has same proportion of 0's, 1's, 2's in both training(Y_train) & testing set(Y_test) \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,stratify=Y, test_size=0.25,random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f26e5bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n",
      "(500,)\n",
      "(1500,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0ae26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize text to numbers using func. CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fce71006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8b2ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vec.fit_transform(X_train).toarray() # convert X_train into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "059c9e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f628adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vec.transform(X_test).toarray() # convert X_test into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6961db74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5784a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will fit the Naive Bayes model to the training data\n",
    "from sklearn.naive_bayes import MultinomialNB   # multinomial for multiple classes, Gaussian for binary classes\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "725d6db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,Y_train)  # train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c67c935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9433333333333334"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, Y_train) # score of the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "52d29e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will predict the test data \n",
    "Y_pred = classifier.predict(X_test) # predict the class of Y for the given testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0cc32461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2,\n",
       "       2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0,\n",
       "       0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2,\n",
       "       2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2,\n",
       "       2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2,\n",
       "       0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2,\n",
       "       2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "934f907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 0), (2, 2), (2, 0), (0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 0), (0, 2), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (0, 2), (2, 2), (1, 2), (2, 2), (2, 2), (2, 2), (2, 0), (2, 2), (0, 2), (0, 2), (2, 2), (0, 0), (0, 2), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (2, 0), (2, 2), (0, 2), (0, 2), (0, 2), (2, 2), (2, 2), (0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (0, 2), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (0, 2), (0, 2), (2, 0), (2, 0), (2, 2), (2, 2), (2, 2), (0, 0), (0, 0), (2, 0), (0, 0), (2, 2), (0, 0), (2, 2), (2, 2), (0, 2), (2, 2), (0, 2), (0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (1, 2), (0, 0), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (0, 0), (1, 2), (2, 0), (2, 2), (2, 2), (2, 2), (0, 0), (0, 0), (0, 0), (2, 2), (0, 0), (2, 2), (0, 0), (0, 2), (0, 0), (2, 2), (2, 2), (0, 2), (2, 2), (2, 0), (0, 0), (0, 2), (2, 2), (0, 2), (2, 2), (0, 0), (0, 0), (2, 2), (2, 2), (2, 2), (0, 2), (0, 2), (0, 0), (0, 0), (2, 2), (2, 2), (2, 0), (0, 0), (2, 2), (0, 2), (1, 2), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (0, 0), (0, 2), (0, 2), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (2, 0), (2, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 0), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (0, 2), (2, 2), (0, 2), (2, 2), (2, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (2, 2), (2, 2), (0, 0), (0, 2), (2, 2), (2, 2), (2, 0), (0, 2), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (2, 0), (2, 2), (2, 0), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (2, 2), (2, 2), (0, 2), (2, 0), (2, 0), (0, 2), (2, 2), (2, 2), (0, 2), (0, 2), (2, 2), (2, 2), (2, 0), (0, 2), (0, 2), (2, 0), (0, 0), (2, 2), (0, 0), (1, 2), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 0), (2, 2), (2, 2), (2, 2), (0, 0), (2, 0), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (0, 2), (2, 0), (0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 0), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 0), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (0, 0), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 0), (0, 0), (2, 2), (2, 2), (0, 2), (0, 0), (0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (0, 2), (2, 2), (2, 2), (2, 0), (0, 2), (2, 2), (2, 2), (0, 0), (2, 2), (0, 2), (0, 2), (0, 2), (0, 0), (0, 2), (0, 2), (1, 2), (2, 2), (2, 2), (2, 0), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (1, 2), (2, 2), (2, 2), (0, 0), (0, 2), (2, 0), (2, 2), (2, 0), (0, 0), (2, 2), (2, 0), (2, 2), (2, 0), (0, 0), (0, 2), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (0, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (2, 0), (0, 2), (0, 2), (0, 2), (0, 0), (0, 2), (0, 0), (0, 2), (2, 0), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (0, 2), (0, 0), (0, 2), (2, 2), (0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (0, 2), (2, 0), (2, 2), (2, 2), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 0), (0, 0), (2, 0), (0, 0), (0, 0), (2, 2), (0, 0), (0, 2), (0, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 0), (2, 2), (0, 2), (2, 2), (0, 2), (2, 2), (2, 2), (2, 2), (2, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(Y_test, Y_pred))) # compare actual Y with predicted Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "287c7f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59   0  90]\n",
      " [  0   0   7]\n",
      " [ 39   0 305]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.40      0.48       149\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.76      0.89      0.82       344\n",
      "\n",
      "    accuracy                           0.73       500\n",
      "   macro avg       0.45      0.43      0.43       500\n",
      "weighted avg       0.70      0.73      0.70       500\n",
      "\n",
      "Multinomial Naive Bayes model accuracy: 0.728\n"
     ]
    }
   ],
   "source": [
    "# model evaluation \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report # import these functions from metrics sublib.\n",
    "cfm = confusion_matrix(Y_test,Y_pred)  #confusion matrix\n",
    "print(cfm)\n",
    "\n",
    "print('classification report')  # classification report\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "acc = accuracy_score(Y_test,Y_pred)  # accuracy of the model\n",
    "print('Multinomial Naive Bayes model accuracy:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "80a3d4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model validating \n",
    "classifier.predict(vec.transform(['because a person can see the positives']).toarray())  # we can pass any text for testing our model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2125a",
   "metadata": {},
   "source": [
    "2 means positive sentiment which is also confirmed by our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "642f30e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(vec.transform(['negatives of that culture']).toarray()) #0 means negative sentiment which is also confirmed by our dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e66b5e",
   "metadata": {},
   "source": [
    "0 means negative sentiment which is also confirmed by our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7195dcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(vec.transform(['terrorism']).toarray())  #negative sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f083173",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "Our model correctly perform the sentiment analysis to understand the general sentiment (positive, negative, neutral) expressed in these posts i.e. our model can classify the unseen blog post as positive, negative or neutral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8971504b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
